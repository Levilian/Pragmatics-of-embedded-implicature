\documentclass[leqno,12pt]{article}

\input{preamble}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Embedded implicatures as pragmatic inferences under compositional lexical uncertainty}
\author{Christopher Potts, Daniel Lassiter, Roger Levy, and Michael
  C. Frank}
\maketitle

\begin{abstract} 
  How do comprehenders reason about pragmatically ambiguous scalar
  terms like \word{some} in complex syntactic contexts?  In Gricean
  theories of conversational implicature, local exhaustification of
  such terms (`only some') is predicted to be impossible if it does
  not strengthen the literal meaning, whereas grammatical accounts of
  implicature predict such construals to be available. Recent
  experimental evidence supports the availability of these local
  enrichments, but the grammatical theories that this evidence
  supports do not provide viable mechanisms for weighting such
  construals against others. We propose a probabilistic model that
  combines previous work on pragmatic inference under `lexical
  uncertainty' with a more detailed model of compositional
  semantics. We show that this model makes accurate predictions about
  new experimental data on embedded implicatures in both non-monotonic
  and downward-entailing semantic contexts. In addition, the model's
  predictions can be improved by the incorporation of neo-Gricean
  hypotheses about lexical alternatives. This work thus contributes to
  a synthesis of grammatical and probabilistic views on pragmatic
  inference.
\end{abstract}

  % How do comprehenders reason about the meaning of pragmatically
  % ambiguous scalar terms like `some' in complex syntactic contexts?
  % In Gricean theories of conversational implicature, comprehenders
  % should consider only the set of global alternatives; but on recent
  % grammatical accounts, locally-enriched meanings should be available
  % as well. Recent experimental evidence supports the availability of
  % these local interpretations, but the grammatical theories that this
  % evidence supports do not provide a viable mechanism for weighting
  % them against other possible interpretations. We propose a
  % probabilistic model that combines previous work on pragmatic
  % inference under `lexical uncertainty' with a more detailed model of
  % compositional semantics. We show that this model makes accurate
  % predictions about new experimental data on embedded implicatures in
  % both non-monotonic and downward-entailing contexts. In addition, the
  % model's predictions can be improved by the incorporation of
  % neo-Gricean hypotheses about lexical alternatives. This work thus
  % contributes to a synthesis of grammatical and probabilistic views on
  % pragmatic inference.

 % \citet{Chemla:Spector:2011} present experimental evidence that
 %  scalar terms like \word{some} in the scope of non-monotonic
 %  quantifiers can be locally enriched to an exhaustified meaning
 %  (`only some'). Such construals are predicted not to occur on Gricean
 %  accounts of conversational implicature, but they are easily within
 %  reach of recent grammar-driven theories like that of
 %  \citealt{ChierchiaFoxSpector08}.  We propose a model that 
 %  embraces the semantic insights of grammar-driven theories, but also offers
 %  a pragmatic explanation for how implicatures arise. The model
 %  straightforwardly synthesizes \posscitet{Bergen:Levy:Goodman:2014}
 %  `lexical uncertainty' model with a full compositional
 %  semantics. After describing it in detail, we present new
 %  experimental evidence that people arrive at locally enrichments, not
 %  just in non-monotonic environments but also (and more
 %  controversially) in downward-entailing ones. We then show not only
 %  that our model generates local enrichments, but also that its
 %  predictions are highly correlated with our experimental data, and
 %  that these predictions can be improved by incorporating neo-Gricean
 %  hypotheses about lexical alternatives.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\marginnote{This section heading seems just right to me. Is there a problem with it I am overlooking? MF's alternative is commented-out.}

%\section{Interactions of pragmatics and grammar}\label{sec:introduction}
\section{Conversational implicature: Interacting with grammar}\label{sec:introduction}

The linguistic forms that discourse participants exchange with each
other routinely underrepresent the speaker's intended message and
underdetermine the listener's inferences. \citet{Grice75} famously
provided a philosophical framework for understanding the driving
forces behind such pragmatic enrichment. At the heart of this
framework are \tech{conversational implicatures}: social, cognitively
complex meanings that discourse participants create jointly in
interaction.

Perhaps the best-studied examples of language users going beyond the
literal semantics involve weak terms like \word{some} being
strengthened to exclude their communicatively stronger alternatives,
giving rise to construals like `some and not all' or `only some'.
Such inferences are often called \tech{scalar conversational
  implicatures} (SIs), and they are widely assumed to arise via the
same social inferencing mechanisms that are at work in other
implicatures.  However, this assumption has always been
controversial. Even \citeauthor{Grice75} suggested that SIs might be
closer to the grammar than other implicatures (p.~56; see also
\citealt{Levinson00,SperberWilson04,Bach06}), and recent
grammar-driven accounts are framed in direct opposition to an
implicature analysis.  For example,
\pgcitet{ChierchiaFoxSpector08}{2316} write, ``the facts suggest that
SIs are not pragmatic in nature but arise, instead, as a consequence
of semantic or syntactic mechanisms''. The ensuing debates have
stimulated new insights, pushing researchers to identify and evaluate
previously unnoticed consequences of the two broad positions.

Much of the debate between Gricean and grammar-driven accounts has
centered around what we informally called \tech{embedded implicatures}
--- cases where a pragmatically enriched interpretation seems to be
incorporated into the compositional semantics. Such readings seem
initially to demand implicature-enriched semantic representations.
However, many of the relevant examples have received straightforward
Gricean accounts in which the embedding is simulated by the
interaction of semantic content with contextual assumptions
\citep{Russell06,Geurts09}. This reduces the power of such examples to
decide in favor of one side or the other.

\citet{Chemla:Spector:2011} study a wide range of embedded
implicatures involving scalar terms in the scope of quantified
phrases, providing experimental evidence that listeners reliably
perceive such readings. They show that many of these listener
inferences are amenable to Gricean treatments with no need for the
pragmatics to intrude on the semantics. However, they go on to
identify a class of examples that will not admit such a treatment:
scalar terms in the scope of non-monotone quantifiers, as in
\word{Exactly one player hit some of his shots}. In such cases, the
interpretation enriched by an embedded implicature (\word{\ldots some but not all of his shots})
does not entail the literal meaning, whereas the Gricean analysis of
scalar terms can only strengthen literal meanings.

% \marginnote{MCF: Pared down and revised description of
%   contributions. Particularly moved the parts on lexical uncertainty
%   down below. We want to acknowledge contributions, but not at the expense of
%   making this intro inaccessible.}

In this paper, we reproduce the central qualitative result of
\citet{Chemla:Spector:2011} using more naturalistic experimental
stimuli and a more direct method of interpreting participants'
responses. Like \citeauthor{Chemla:Spector:2011}, we find that scalar
terms in non-monotone environments support implicature inferences. We
hope that these results bolster \citeauthor{Chemla:Spector:2011}'s
conclusions and help to address the skeptical reactions of
\citet{geurts-vantiel:2013:scalar}. In our view, this evidence points
to a role for compositional semantics in understanding
implicatures. But pragmatic factors also play a crucial role: even
embedded implicatures arise only with proper contextual support
\citep{Russell06,ChierchiaFoxSpector08,Geurts:2011,Chemla:Spector:2011}.

To describe the complementary roles of grammar and pragmatics in
embedded implicatures, we propose a model that both embraces the
compositional insights of \citeauthor{ChierchiaFoxSpector08} and
characterizes how speakers arrive at such construals. This model is in
the tradition of \tech{rational speech act} models
\citep{Frank:Goodman:2012,Goodman:Stuhlmuller:2013} and \tech{iterated
  best response} models \citep{Franke09DISS,Jaeger:2011}, and builds
most directly on the \tech{lexical uncertainty} model of
\citet{Bergen:Goodman:Levy:2012} and
\citet{Bergen:Levy:Goodman:2014}. Our variant of this model describes
how discourse participants coordinate on the right logical forms
(implicature-rich or not), seeking to retain the insights of Gricean
accounts while paying close attention to the details of semantic
composition.

We show not only that our model captures the qualitative pattern of
implicature behaviors that \citeauthor{Chemla:Spector:2011} found, but
also makes quantitative predictions that are highly correlated with people's actual
inferential behavior in context. In addition, we show that these
correlations can be improved if the set of refinements is lexically
constrained, in keeping with broadly neo-Gricean views of scalar
implicature \citep{Horn72,Gazdar79b,Gazdar79a,SchulzVanRooij06}.  Our
results suggest that the full theory of implicature depends
substantively on the fine details of semantic composition \emph{and}
broader considerations of rational interaction. This is perhaps a
departure from \posscitet{Grice75} particular conception of pragmatic
meaning, but it is well-aligned with his general theory of meaning and
intention \citep{grice57}.  In view of our experimental results, the chief advantage
of our model is that it makes quantitative predictions that are easily
and rigorously linked with our human response patterns. In other
words, the model makes predictions not only about what is possible in
terms of pragmatic inferences but also about how likely those
inferences are. 

Our broader position is that grammar-driven accounts and Gricean
accounts are not in opposition, but rather offer complementary
insights.  When communicating in natural languages, people are relying
on linguistic conventions to try to identify and convey each other's
intentions. All sides in the debate acknowledge this mix of
grammatical and interactional factors. \posscitet{Grice75} definition
of conversational implicature is interactional, but his maxim of
manner embraces a role for language. By introducing additional devices such as Horn scales, Neo-Griceans expand this role
into areas Grice addressed with the maxims of quantity, quality, and
relevance. \citet{Sperber95} and \citet{Bach94} characterize many
kinds of pragmatic enrichment as inferences about logical forms. And
\citet{ChierchiaFoxSpector08} invoke broadly Gricean pressures to
explain how speakers and listeners coordinate on whether to posit
implicature-rich logical forms or more literal ones. Thus, there is
substantially more consensus than the rhetoric often suggests.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Implicature, enrichment, and embedding}\label{sec:implicature}

In this section, we describe embedded implicatures, seeking to
identify their relevance for Gricean and grammar-driven
frameworks. Under \posscitet{Grice75} original definition,
conversational implicature is essentially an act of social
cognition. The original definition is somewhat underspecified, and
fleshing it out into a precise formulation is challenging
\citep{Hirschberg85}, but the guiding idea seems clear.  The listener
assumes that that the speaker is cooperative, in the Gricean sense of
rational interaction. However, the listener is confronted with an
utterance $U$ with content $p$ that meets this assumption only if certain additional conditions are met. The listener can resolve this tension by positing that these conditions are in fact met; in many (but not all) cases, this means inferring that the speaker actually
intended for the listener to infer the truth of an additional proposition $q$, or of a different but related proposition $q'$. By this reasoning, the listener is able to reconcile the observation that the speaker chose to utter $U$ with the
assumption that the speaker is behaving in a cooperative manner.

In the current work, we do not try to make the above description more
rigorous. The model that we develop does not depend on an
independently formulated definition of implicature, but rather seeks
to derive such meanings from more basic considerations about how
speakers and listeners reason about each other whenever they
interact. Similarly, the model of \citet{ChierchiaFoxSpector08} is
noncommittal about the reality of conversational implicatures per
se. For them, `conversational implicature' can be seen as an informal
label for a certain class of logical forms, rather than a conceptual
primitive. With this in mind, we use the notion of conversational
implicature only to articulate the central empirical focus of this
paper --- embedded scalar terms --- and the challenges they pose for
Gricean accounts.

On the classic Gricean account, scalar implicatures arise when the
imperative `Be as informative as is required' (a subclause of the
maxim of quantity) is in tension with another pragmatic pressure related to cooperative communication. The
opposing force can take many forms, for example, relating to
considerations of politeness, discretion, or secrecy, but it is
usually attributed to the maxim of quality, which instructs speakers
to say only what they have strong positive evidence for. For instance,
imagine a sportscaster who has observed the outcome of a single round
of a basketball tournament and is reporting on it as news. If the
sportscaster says \eg{some}, then she will likely implicate that
Player~A did not make all of his shots.
%
\begin{examples}
\item\label{some} Player~A hit some of his shots.
\end{examples}

The scalar implicature follows from a straightforward application of
the above ideas. We assume the sportscaster is cooperative in the
Gricean sense, and knowledgeable and forthcoming about the
events. Why, then, did she opt for a weak statement like
\word{Player~A hit some of his shots} when a stronger statement like
\word{Player~A hit all of his shots} is available and would have been more informative?
If knowledgeability is the only relevant consideration, it must be that she was prevented from using
this stronger form because she does not know it to be true. Together
with our assumption that she observed the full outcome, she can lack
knowledge of this proposition only because it is false, leading to the
implicated meaning that Player~A did not hit all of his shots. In this
way, a listener can enrich the speaker's message.

To make this concrete, suppose that we have two players, A and B, and
that we care (for present purposes) only about whether each of them
hit none, some but not all, or all of his shots. We can identify these
(equivalence classes of) possible worlds with labels like \world{NA}, which means that Player~A
hit none of his shots and Player~B hit all of his shots, and
\world{SS}, which means that both players hit some but not all of
their shots. There are $3^{2} = 9$ such worlds. The literal semantics
of \eg{some} in this context is the proposition given in
(\ref{some-sem}b). Our hypothesized implicature is (\ref{some-sem}c),
the proposition that Player~A did not hit all of his shots.  The
intersection of these two meanings delivers the communicated meaning,
(\ref{some-sem}d).
%
\begin{examples}
\item\label{some-sem}
  \setlength{\tabcolsep}{2pt}
  \begin{tabular}[t]{@{} r@{. \ } l *{9}{c}@{\hspace{18pt}} l}
    a& Worlds:       & \world{NN} & \world{NS} & \world{NA} & \world{SN} & \world{SS} & \world{SA} & \world{AN} & \world{AS} & \world{AA} & \\
    b& Literal:      &            &            &            & \world{SN} & \world{SS} & \world{SA} & \world{AN} & \world{AS} & \world{AA} & `at least some'\\
    c& Implicature:  & \world{NN} & \world{NS} & \world{NA} & \world{SN} & \world{SS} & \world{SA} &            &            &            & `not all' \\
    d& Communicated: &            &            &            & \world{SN} & \world{SS} & \world{SA} &            &            &            & `only some'
  \end{tabular}
\end{examples}

There are many proposals for how to formalize this reasoning. The
common theme running through all of them is that the implicature is
accessible because it is a refinement that strictly entails the
original literal content --- in this example, because the utterance's literal meaning and the implicature are combined into an enriched meaning by intersection. In \citeauthor{Grice75}'s terms, a general
claim is further restricted by the interaction of quantity and
quality.

The above informal reasoning extends to examples like \eg{everysome},
in which \word{some} is in the scope of a universal quantifier.
%
\begin{examples}
\item\label{everysome} Every player hit some of his shots.
\end{examples}
%
In the same general context as before, this can be enriched to convey
that every player hit some but not all of his shots. Making this
reasoning precise is, however, somewhat more challenging than it was
for \eg{some}.  If we take the implicature to be the negation of the
stronger alternative \word{Every player hit all of his shots}, then
the reasoning proceeds as in the first four lines of
\eg{everysome-sem}, which takes us to a meaning (\ref{everysome-sem}d)
that is consistent with one or the other of the players (but not both)
having hit all of his shots. To arrive at the target meaning (every
player hit some but not all of his shots), we must, on this simple
account, posit an auxiliary premise. One example of such a premise is
(\ref{everysome-sem}e); there are many others that will do the job
\citep{Spector:2007:SCALAR}.
%
\begin{examples}
\item\label{everysome-sem}
  \setlength{\tabcolsep}{2pt}
  \begin{tabular}[t]{@{} r@{. \ }l *{9}{c} @{\hspace{18pt}} l }
    a & Worlds:         & \world{NN} & \world{NS} & \world{NA} & \world{SN} & \world{SS} & \world{SA} & \world{AN} & \world{AS} & \world{AA} \\
    b & Literal:        &            &            &            &            & \world{SS} & \world{SA} &            & \world{AS} & \world{AA} & `every hit at least some' \\ 
    c & Implicature:    & \world{NN} & \world{NS} & \world{NA} & \world{SN} & \world{SS} & \world{SA} & \world{AN} & \world{AS} &            & `not every hit every' \\
    d & Result:         &            &            &            &            & \world{SS} & \world{SA} &            & \world{AS} &            & `every hit some; not every hit all'\\    
    e & Aux.~premise:   & \world{NN} &            &            &            & \world{SS} &            &            &            & \world{AA} & `uniform outcomes' \\
    f & Communicated:   &            &            &            &            & \world{SS} &            &            &            &            & `every hit only some'
  \end{tabular}
\end{examples}

Though the need for an auxiliary premise is a noteworthy complication,
it seems within the bounds of a Gricean account, and auxiliary
premises like these might be independently justified
\citep{Russell06}. As in the previous example, the communicated
meaning is an enrichment of the literal content, and Gricean pressures
and contextual assumptions deliver the stronger
meaning. \citet{Geurts:Pouscoulous:2009} and
\citet{Chemla:Spector:2011} home in on this common theme in scalar
implicature calculation and use it to probe the empirical adequacy of
the Gricean framework. Examples like \eg{exactlyonesome} drive their
discussions.  This is a minimal variant of \eg{everysome} with the
subject universal determiner \word{every} replaced by \word{exactly
  one}.
%
\begin{examples}
\item\label{exactlyonesome} Exactly one player hit some of his shots.
\end{examples}

Many people have the intuition that \eg{exactlyonesome} can be used to
describe a situation in which there is exactly one player who scored
some but not all of his shots, which is consistent with some players
having scored all of their shots. The reading is easy to characterize
intuitively: one imagines that \word{some of his shots} has been
locally enriched to \word{some but not all of his shots}, and that
this enriched meaning is the semantic argument to the subject
quantifier. What makes this reading notably different from, e.g.,
\eg{everysome} is that it does not entail the literal reading, as we
see in \eg{exactlyonesome-sem}. The literal semantics is the
proposition in (\ref{exactlyonesome-sem}b), whereas the content of the
\word{\ldots some but not all of his shots} (`Local') construal is
(\ref{exactlyonesome-sem}c), which merely overlaps with it.
%
\begin{examples}
\item\label{exactlyonesome-sem}
  \setlength{\tabcolsep}{2pt}
  \begin{tabular}[t]{@{} r@{. \ } l *{9}{c}@{\hspace{8pt}} l}
    a& Worlds:       & \world{NN} & \world{NS} & \world{NA} & \world{SN} & \world{SS} & \world{SA} & \world{AN} & \world{AS} & \world{AA} & \\
    b& Literal:      &            & \world{NS} & \world{NA} & \world{SN} &            &            & \world{AN} &            &            & `exactly one hit at least some'\\
    c& Local:        &            & \world{NS} &            & \world{SN} &            & \world{SA} &            & \world{AS} &            & `exactly one hit only some' \\
  \end{tabular}
\end{examples}
%
Any theory in which enriched scalar interpretation are always generated by conjunction/intersection, as they are in classical Gricean and neo-Gricean accounts of scalar implicature, will fail to
arrive at (\ref{exactlyonesome-sem}c). Such theories head inexorably
towards a refinement that excludes \world{NA} and \world{AN}, but they
are essentially incapable of `introducing' \world{SA} and \world{AS}.

% \marginnote{New discussion of downward entailing contexts. Foreshadows experimental discussion.}

The issue is even clearer when a scalar term is in the scope of a
downward-monotone operator like \word{no}, as in \word{no player hit
  some of his shots}. In such cases, the embedded enrichment creates a
meaning that is strictly entailed by (weaker than) the literal
meaning:
%
\begin{examples}
\item\label{nosome-sem}
  \setlength{\tabcolsep}{2pt}
  \begin{tabular}[t]{@{} r@{. \ } l *{9}{c}@{\hspace{18pt}} l}
    a& Worlds:       & \world{NN} & \world{NS} & \world{NA} & \world{SN} & \world{SS} & \world{SA} & \world{AN} & \world{AS} & \world{AA} & \\
    b& Literal:      & \world{NN} &            &            &            &            &            &            &            &            & `none hit some' \\
    c& Local:        & \world{NN} &            & \world{NA} &            &            &            & \world{AN} &            & \world{AA} & `none hit only some' \\
  \end{tabular}
\end{examples}

Gricean theories predict that the `Local' reading is unavailable here,
either because of the way pragmatic pressures interact or because
\word{some} is held to be the strongest member of its scale in
negative environments, leaving no room for further
enrichment. Grammar-driven approaches have tended to agree with the
basic empirical assumption, arguing that local enrichment is blocked
in environments where it would strictly weaken the literal content \citep{chierchia2006broaden}. 
 
The empirical evidence is mixed but seems to support the accessibility
of these local interpretations. Modifying an earlier design by
\citet{Geurts:Pouscoulous:2009}, \citeauthor{Chemla:Spector:2011} used
displays involving geometric patterns to assess whether interpreters
could access local-enrichment readings of scalar terms in the scope of
non-monotone and downward-monotone operators. Their findings suggest
that local enrichment readings are available in both contexts,
especially non-monotone ones. Nevertheless, skeptics of local
enrichment have found grounds for challenging
\citeauthor{Chemla:Spector:2011}'s findings. For example, participants
in their experiment clearly struggled with the complex visual
displays, often giving low ratings to true readings and sometimes
giving high ratings to false ones. We believe that the theoretical
challenges posed by embedded implicatures are real, however. In
\secref{sec:exp1}, we describe a new experiment that uses simpler
displays, but that reproduces the core findings of
\citeauthor{Chemla:Spector:2011}'s studies.

% In addition,
% \citeauthor{Chemla:Spector:2011} rely on additional theoretical
% assumptions in order to link their theory to the response patterns
% --- roughly, they must invoke an auxiliary hypothesis that the more
% true construals are available for an ambiguous or underspecified
% sentence, the more confident people will be in their judgment that a
% sentence is true. Whether or not this assumption is valid, the need
% to invoke it opens up further room for criticism.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{\CFS's grammar-driven model}\label{sec:cfs}

This section briefly reviews the grammar-driven model of
\citet{ChierchiaFoxSpector08} (henceforth \CFS).  The approach is
inspired by those of \citet{Chierchia01}, \citet{Sauerland01},
\citet{Spector:2007}, and \citet{Fox:2007,Fox:2009}. There are two
central pieces to the account: a generally available function $\ALT$
that maps words and phrases to their alternatives, and a covert
exhaustification operator $O$.

For $\ALT$, the relevant notion of alternative is familiar from
theories of questions and focus \citep{Groenendijk84,Rooth85,Rooth92}:
we can assume, as a default, that the alternatives for an expression
$\varphi$ is some subset of the items in the same type-theoretic
denotation domain as $\sem{\varphi}$, the meaning of $\varphi$. 
% I think this assumption is not needed ---CP
% Except for the restriction that $\sem{\varphi} \in\ALT(\varphi)$ for
% any $\varphi$.
The precise value of the function $\ALT$ is context-dependent, and
discourse participants are presumed to coordinate on it, just as they
coordinate on the meanings of deictic or discourse-bound pronouns,
elided phrases, and other pragmatically controlled free variables.

The basic exhaustification operator is given in \eg{def:O}
\citep{Spector:2007,Fox:2007,Fox:2009,Magri:2009,ChierchiaFoxSpector08}.\footnote{This
  is not the operator that those authors ultimately favor, since it
  requires some implicit restrictions on allowable $\ALT$ functions in
  order to get the right inferences.  The final version has the same
  form as \eg{def:O} but further restricts $\ALT$.}
%
\begin{examples}
\item\label{def:O}
  $\OALT(\varphi) = 
  \sem{\varphi} \sqcap \bigsqcap\set{ -q : q \in \ALT(\varphi) \wedge \sem{\varphi} \not\entails q}$ 
\end{examples}
%
The $O$ operator maps an expression $\varphi$ to one that entails
$\sem{\varphi}$ and excludes the denotations of expressions in $\ALT(\varphi)$ that are strictly
stronger than $\sem{\varphi}$. When dealing with truth-functional
expressions, we can regard $\sqcap$ as boolean conjunction and
$\entails$ as a material conditional, but the definition should be thought of
as broad enough to include any kind of partial ordering
\seccitet{Hirschberg85}{4}.

Part of the case for a grammar-driven view is that it uses pieces of
semantic theory that are independently needed. In particular,
exhaustification is at the heart of \posscitet{Groenendijk84} theory
of questions and their answers. The above operator is a common
proposal for the meaning of \word{only} (for discussion:
\citealt{Rooth96,Buring01,BeaverClark08}).  \citet{SchulzVanRooij06}
use exhaustification for implicature calculation (see also
\citealt{deJagerVanRooij07}).  (For critical discussion, see
\citealt{Alonso-Ovalle:2008} and \citealt{Gajewski:2012}.) While \CFS\
are cautious about making direction connections between $O$ and these
other phenomena (p.~2304), the correspondences are nonetheless
noteworthy.

Those are the technical pieces. The proposal can then be summarized
easily: $O$ operators can appear anywhere in the logical form of a
sentence, perhaps subject to additional restrictions and general
preferences (see \CFS: $\S$4.6). To see the effects that this could
have, let's return to the examples involving \word{some} that we
reviewed in \secref{sec:implicature}. Simplifying slightly, let's
suppose that \word{some shot} denotes the set of sets in \eg{someshot}
--- the set of all sets that have a non-empty intersection with the
set of shots.
%
\begin{examples}
\item\label{someshot} $\sem{\word{some shot}} = \set{Y : \sem{\word{shot}} \cap Y \neq \emptyset}$
\end{examples}
%
Consider a domain of three entities $\set{a,b,c}$, and assume that
$\sem{\word{shot}} = \set{a,b}$. Then the above is equivalent to the
set of sets circled in green in \figref{fig:qspace}. Now suppose that
$\ALT(\word{some shot})$ is defined as follows:
%
\begin{examples}
\item\label{altsome} $\ALT(\word{some shot}) =  
  \set{
    \sem{\word{some shot}}, 
    \sem{\word{every shot}}, 
    \sem{\word{no shot}}
  }$
  \begin{examples}
  \item $\sem{\word{some shot}}$ as in \eg{someshot} \hfill (green circle in \figref{fig:qspace})
  \item $\sem{\word{every shot}} = \set{Y : \sem{\word{shot}} \subseteq Y}$ \hfill (purple circle in \figref{fig:qspace})
  \item $\sem{\word{no shot}} = \set{Y : \sem{\word{shot}} \cap Y = \emptyset}$  \hfill (orange circle in \figref{fig:qspace})
  \end{examples}
\end{examples}

\begin{figure}[tp]
  \centering
  \newcommand{\labelednodeleft}[2]{\put(#1){\makebox(0,0)[l]{#2}}}
  \newcommand{\labelednode}[2]{\put(#1){\makebox(0,0){#2}}}
  \newcommand{\picline}[3]{\put(#1){\line(#2){#3}}}
  \setlength{\unitlength}{1.2cm}
  \begin{picture}(9.5,4.5)   
    \labelednode{2.75,3}{$\set{a,b,c}$}
        
    \picline{0.75,2.2}{3,1}{1.8}
    \picline{4.75,2.2}{-3,1}{1.8}
    \picline{2.75,2.2}{0,1}{0.6}
    \labelednode{0.5,2}{$\set{a,b}$}
    \labelednode{2.75,2}{$\set{a,c}$}
    \labelednode{5,2}{$\set{b,c}$}
    \picline{2.5,1.2}{-3,1}{1.8}
    \picline{2.75,1.2}{0,1}{0.6}
    \picline{3.0,1.2}{3,1}{1.8}    
    \picline{0.5,1.2}{0,1}{0.6}
    \picline{0.75,1.2}{3,1}{1.8}
    \picline{4.75,1.2}{-3,1}{1.8}
    \picline{5,   1.2}{0,2}{0.6}

    \labelednode{0.5,1}{$\set{a}$}
    \labelednode{2.75,1}{$\set{b}$}
    \labelednode{5,1}{$\set{c}$}

    \linethickness{2pt}
    {\color{cborange}\put(4.9,1){\oval(0.65,0.65)}}
    {\color{cbpurple}\rotatebox{20}{\put(1.6,2.1){\oval(3.5,0.85)}}}
    {\color{cbgreen}\rotatebox{20}{\put(1.72,1.5){\oval(5.7,2.65)}}}
    {\color{gray}\rotatebox{20}{\put(1.25,1.18){\oval(5.5,1.48)}}}

    \labelednodeleft{4,4}{{\color{cbgreen}$\sem{\word{some shot\/}}$}}
    \labelednodeleft{4,3}{{\color{cbpurple}$\sem{\word{every shot\/}}$}}
    \labelednodeleft{4,2}{{\color{darkgray}$\sem{\OALT(\word{some shot\/})}$ as in \eg{altsome}}}
    \labelednodeleft{4,1}{{\color{cborange}$\sem{\word{no shot\/}}$}}

  \end{picture}
  \caption{Given a domain $\set{a,b,c}$ with $\sem{\word{shot}} = \set{a,b}$,
    $\sem{\word{some shot}}$ is equal to the set of sets circled in green,
    $\sem{\word{every shot}}$ to the set of sets in purple, and
    $\sem{\word{no shot}}$ to the set of sets in orange. If $\OALT(\word{some shot})$ 
    contains  $\sem{\word{every shot}}$, then \word{some shot} is 
    refined to exclude the purple subset.}
  \label{fig:qspace}
\end{figure}

The presence of $\sem{\word{some shot\/}}$ has no effect because it is
identical to the input. Similarly, all quantifiers that are weaker
than the input have no effect if included in the $\ALT$ set. The
presence of $\sem{\word{no shot\/}}$ has no effect because it
contradicts the input, so its complement is weaker than the input.
The presence of $\sem{\word{every shot\/}}$ will, though, be meaningful,
as long as we assume that $\sem{\word{shot\/}} \neq \emptyset$.  In that
case, $\OALT(\word{some shot\/})$ will denote the subset in gray in
\figref{fig:qspace}.  This is equivalent to the intersection of
$\sem{\word{some shot\/}}$ and the complement of
$\sem{\word{every shot\/}}$ in the powerset of the domain.  In other
words, it expresses \word{some and not all}, the intuitively
implicature-rich interpretation.

Because $\OALT$ is embeddable, syntactic constituents like
$\OALT(\word{some shot})$ can appear in the scope of quantifiers.
Implicature-rich versions of \eg{some}, \eg{everysome}, and
\eg{exactlyonesome} are thus available --- potentially usable by
speakers and inferable by listeners just like any other semantic
resolution for an underspecified form in context.

As we noted in the introduction, \CFS\ draw a firm rhetorical
distinction between their proposal and the Gricean approach to
pragmatics. They state, ``the goal of this paper is to challenge the
neo-Gricean approach to SIs'' (p.~2303), and, as we said, they later
write that ``the facts suggest that SIs are not pragmatic in nature
but arise, instead, as a consequence of semantic or syntactic
mechanisms'' (p.~2316). The sense in which their account reflects this
position is clear: to characterize implicatures, we need not consider
the interactional setting or try to model the speaker and
hearer. Rather, we can just describe a specific class of logical
forms.

However, this position is tempered by \CFS's pervasive appeals to
Gricean reasoning.  The authors' specific examples are generally
placed in contexts that support the target implicatures by ensuring
that they are relevant, informative, and truthful.  They concede that
``aspects of the Gricean picture are sound and effective''
(p.~2299). And, in summarizing their account, they make explicit the
role that Gricean pragmatics must play in helping discourse
participants to coordinate on the right logical forms:
%
\begin{quote}
  one can capture the correlation with various contextual
  considerations, under the standard assumption (discussed in the very
  beginning of this paper) that such considerations enter into the
  choice between competing representations (those that contain the
  operator and those that do not). (p.~2317)
\end{quote}

%\marginnote{DL: changed ``always underdetermines'' to ``frequently'', since whether O-insertion generates ambiguity depends on details of the sister's denotation and its alternative set.}

The coordination problem that \citeauthor{Grice75} sought to solve
therefore remains, though its precise form is different. In the
context of \CFS's theory, the discourse participants must coordinate
on the nature of the function $\ALT$.  Similarly, because the language
permits silent, embedded $O$ operators in many positions, the
speaker's signal frequently underdetermines her intended message; a
given surface form $U$ might be consistent with logical forms that
encode implicatures and those that don't. The speaker must therefore
rely on the listener to select the right one.  From this perspective,
implicature calculation amounts to reasoning about which logical form
was intended. How this coordination happens has not been a focus of
grammar-driven accounts, but the above quotation suggests that
communicative pressures like those \citeauthor{Grice75} identified
guide the process.

Summarizing so far, we have evidence from
\posscitet{Chemla:Spector:2011} experiments that some implicatures
require, in some sense, local enrichment of embedded content via
enhanced logical forms. Traditional Gricean accounts seem unable to capture such
cases, though such accounts excel at characterizing how speakers and
listeners coordinate on implicatures in simpler cases. \CFS\ define a
model in which local calculation is immediate, but they do not venture
an account of how discourse participants coordinate on the right
logical forms when more than one is allowed by the grammar. Stepping
back, we see that each side clearly has something to contribute. We
now turn to the task of developing a synthesis of the two approaches:
a model that formally implements pragmatic reasoning over complex,
compositionally defined logical forms and that is able to achieve the
readings that seem to demand local enrichment. The technical details
of the compositional model are different from \CFS's, and the
technical details of the pragmatic account are different from
\citeauthor{Grice75}, but we hope that it combines the best aspects of
both approaches.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The compositional lexical uncertainty model}\label{sec:model}

% \marginnote{MCF: Added RSA models to the cite list. Also planted the
%   Bergen et al. text here, which works for me because it gives a model
%   intuition right before the formal description.}

We now present our mixed semantic--pragmatic model, which can be seen
as a conceptual fusion of the Montagovian semantic perspective in
\citet{Lewis70GS}, the signaling systems of \citet{Lewis69}, the
probabilistic rational speech acts perspective of
\citet{Frank:Goodman:2012} and \citet{Goodman:Stuhlmuller:2013}, and
the iterated best response model of \citet{Jaeger:2007,Jaeger:2011}
and \citet{Franke09DISS}.  Our Python implementation of the model is
available from the website for this paper.

The model we use here is a direct extension of the lexical uncertainty
model of \citet{Bergen:Goodman:Levy:2012} and
\citet{Bergen:Levy:Goodman:2014}. The lexical uncertainty model
defines production and interpretation as recursive processes in which
speakers and listeners reason jointly about the state of the world and
the nature of the linguistic system they are
using. \citeauthor{Bergen:Levy:Goodman:2014} show that this model
captures a wide range of well-studied classes of implicature,
including many embedded implicatures involving scalar terms. Our
extension simply allows for greater diversity in the semantic lexicon
and includes more complex aspects of semantic composition. Thus, in
many ways, our central finding is that
\citeauthor{Bergen:Levy:Goodman:2014}'s model predicts embedded
implicatures in non-monotone contexts if it is combined with a full
theory of semantic composition.

The crucial feature of our model is its notion of \tech{lexical
  uncertainty}. The discourse participants are not presumed to share a
single, fixed lexicon. Rather, they consider many lexica, and their
communicative behavior, in both production and interpretation, is
guided by their best attempts to synthesize the information from these
varied sources. Thus, in the sentences of interest, the discourse
participants might entertain multiple senses for an embedded
\word{some}, including not only its `at least' meaning but also the
`only some' meaning that corresponds to its enrichment by scalar
implicature. This uncertainty carries through the compositional
semantics to deliver embedded implicature readings. From this
perspective, \citeauthor{ChierchiaFoxSpector08}'s model is also a
lexical uncertainty model: for them, a given token of \word{some} can
take on multiple senses depending on the presence and nature of silent
embedded operators in the logical form. Our extension of
\citeauthor{Bergen:Levy:Goodman:2014}'s model shows how this
uncertainty guides pragmatic reasoning, and it furthermore shows that
the uncertainty need not be fully resolved in order for robust
pragmatic inferences to go through.

% As we said above, the model is a minor extension of the one
% presented in detail in \citet{Bergen:Levy:Goodman:2014}, which
% builds on the presentation of \citet{Bergen:Goodman:Levy:2012}. Our
% technical contribution here is to define an expanded view of lexical
% uncertainty and to study the effects this expansion has in a fully
% compositional intensional logic with quantifiers. Our Python
% implementation of the model is available from the website for this
% paper.

%=====================================================================

\subsection{Grammar fragment}\label{sec:grammar}

%\todo{The grammar is hard to work with because of its intensional aspects. I am open to rewriting it using lambdas. This will require a more convoluted definition of refinement.}

\Tabref{tab:grammar} gives the intensional fragment that we use
throughout the remainder of this paper, both to explain how our
pragmatic model works and to conduct our experimental analyses in
\secref{sec:exp1}. It is our base lexicon, subject to refinement as
part of pragmatic inference.

The formal presentation is influenced by that of \citet{Muskens95}:
all of the denotations are sets, and the rules of semantic composition
(the final four lines) combine them using operations that are formally
akin to functional application. Our motivation for this less familiar
presentation is that it makes it easy to define a uniform notion of
refinement throughout the lexicon.

\begin{table}[t]
  \centering
  \renewcommand{\arraystretch}{1.2}
  \begin{tabular}[c]{r@{ $\rightarrow$ }l l}
    \toprule
    \multicolumn{2}{c}{Syntax}     & Denotation of the lefthand side of the syntax rule\\
    \midrule
    N   & \word{person}      & $\set{\tuple{w, x} : x \text{ is a person in } w}$ \\
    N   & \word{shot}        & $\set{\tuple{w, x} : x \text{ is a shot in } w}$ \\
    \Vt & \word{hit}         & $\set{\tuple{w, x, y} : x \text{ hit } y \text{ in } w}$ \\
    \Vi & \word{scored}      & $\set{\tuple{w, x} : \exists y \ x \text{ hit } y \text{ in } w}$ \\
    D   & \word{some}        & \genericquantifier{\cap}{\neq \emptyset} \\
    D   & \word{every}       & \genericquantifier{\subseteq}{} \\
    D   & \word{no}          & \genericquantifier{\cap}{= \emptyset} \\
    D   & \word{exactly one} & \genericquantifier[cardinality]{\cap}{= 1} \\
    NP  & \word{Player A}     & \genericpn{\playera} \\
    NP  & \word{Player B}     & \genericpn{\playerb} \\
    NP  & \word{Player C}     & \genericpn{\playerc} 
    \\[1ex]    
    NP  & D N         & $\set{\tuple{w, Y} : \tuple{w, \gsem{N}, Y} \in \gsem{D}}$ \\
    VP  & \Vt\ NP     & $\set{\tuple{w, x} :  \set{\tuple{w, y} :  \tuple{w, x, y} \in \gsem{\Vt}} \in \gsem{NP}}$ \\
    VP  & \Vi         & $\gsem{\Vi}$ \\
    S   & NP VP       & $\set{w : \tuple{w, \gsem{VP}} \in \gsem{NP}}$ \\
    \bottomrule
  \end{tabular}
  \caption{Interpreted grammar fragment. The left column defines a context-free grammar,
    and the right column gives its recursive interpretation in an intensional model
    $\tuple{\Domain, \Worlds, \sem{\cdot}}$, where $\Domain$ is a set of entities,
    $\Worlds$ is a set of possible worlds, and $\sem{\cdot}$ is a semantic interpretation
    function. Assume $x, y \in \Domain$, $w \in \Worlds$, and $X, Y \subseteq (\Worlds \times \Domain)$.}
  \label{tab:grammar}
\end{table}

%=====================================================================

\subsection{Refinement}\label{sec:refine}

%\marginnote{This section has been substantially revised in terms of prose and technical content.}

The grammar in \tabref{tab:grammar} contains both lexical entries and
rules of semantic combination. We assume that the rules are fixed.
The lexical entries, on the other hand, are merely a starting point
for linguistic communication --- a set of somewhat negotiable
conventions. You might assume that \word{couch} and \word{sofa} are
synonymous, but if I say ``It's a couch but not a sofa'', you'll learn
something about my lexical representations and perhaps adjust your own
accordingly for the purposes of our interaction. In semantics, we like
to imagine that word meanings are fixed across speakers and context,
but in fact they are sometimes idiosyncratic and usually adaptable
\citep{Clark97}. 

% I am not sure I understand this comment. Is it just that `lefthand
% side' was ambiguous? If so, I think I've fixed it. If not, I don't
% see what the issue is. Maybe the comment expresses a preference for
% giving lexical denotations and then having one rule that says a
% non-branching mother is interpreted as identical to its daughter.
% If so, that will take up more space and require more notation, but
% I guess we could do it.
%
%\marginnote{`lefthand side' not quite right in figure 2 column labels; `rule/item'? relatedly, do you envision rules having denotations in this grammar?}

The `lexical uncertainty' aspects of our model are designed to capture
this variability. The core notion is that of lexical
\tech{refinement}, as defined in \eg{refinement}.
%
\begin{examples}
\item\label{refinement} 
  \begin{examples}
  \item Let $\varphi$ be a set-denoting expression. $X$ is a
    \tech{refinement} of $\varphi$ iff $X \neq \emptyset$ and
    $X \subseteq \sem{\varphi}$.
  \item\label{refine} $\Refine(\varphi)$, the set of refinements for
    $\varphi$ in context $c$, is constrained so that
    $\sem{\varphi} \in \Refine(\varphi)$ and
    $\Refine(\varphi) \subseteq \wp(\sem{\varphi}){-}\emptyset$
  \end{examples}
\end{examples}
%
The full possible refinement space for a lexical item is the powerset
of its denotation minus the empty set. In a functional presentation of
the interpreted fragment, this could instead be defined in terms of
the subfunctions of a given denotation using a cross-categorical
notion of entailment. With \subeg{refinement}{refine}, we allow that
contexts can vary in how much of the full refinement space they
utilize. They can be as small as the original denotation, trivializing
the uncertainty, or as large as the full power set (minus the empty
set).

The guiding idea is that, in interaction, pragmatic agents reason
about possible refinements of their lexical items, with the base
lexical meaning serving as a kind of focal point for the interaction
\citep{Franke09DISS}.  Intuitively, one can imagine that part of what
it means to be a responsible interlocutor is to make inferences based
on the speaker's behavior not only about the world information she
would like to convey but also about the nature of the lexicon she is
using.

As we noted above, \CFS's model is a kind of lexical uncertainty
model. For any given lexical item that one hears, the speaker might
have in mind its literal content $\sem{\varphi}$ or one of the many
enrichments available with $\OALT(\varphi)$ for different choices of
$\ALT$. Similarly, we admit the trivial refinement set
$\Refine(\varphi) = \set{\sem{\varphi}}$ as well as supersets of
it. The major technical difference lies in how these sets of
denotations enter into the compositional semantics. For \CFS, the
alternatives all contribute to a single denotation, whereas our model
keeps them separate during the semantic composition, synthesizing them
only for pragmatic inference. In terms of \figref{fig:qspace}, we saw
that \CFS's theory uses $\OALT$ to create a single refined meaning for
\word{some shot}, represented by the set of sets in the gray circle
(`some, not all'). Our theory of refinement could create one lexicon
for every non-empty subset of the green circle. So, in addition, to
considering `some, not all', we also admit lexica in which \word{some
  player} denotes $\set{\set{a}, \set{b}}$ (`exactly one shot'),
lexica in which it denotes $\set{\set{a,b,c}}$ (`every shot'), lexica
in which it denotes $\set{\set{a,b,c},\set{a}}$ (no obvious
paraphrase), and so forth for all the other subsets of the green
circle. These are all potential results of $\OALT(\word{some shot})$
for some choice of $\ALT$, and our theory can be regarded as one that
reasons in terms of all of these options.

% % I'm thinking the figure is concrete enough, but this could be added
% % back too. The only trick is that, since we now allow different kinds
% % of refinement, it needs to be emphasize that it depicts just one
% % example. 
%
% Here is an example of what refinement looks like, using a proper name
% and extensionalizing the semantics so that the example fits onto the
% page.  The important thing here is that we entertain lexica like the
% third-listed one in \subeg{refinement-ex}{ex-refinements} in which
% \word{Player A} means `Only Player A'.
%
% \begin{examples}
% \item\label{refinement-ex}
%  
%   \begin{examples}
%   \item $D = \set{a,b}$
%   \item $W = \set{w_{1}, w_{2}}$
%   \item  $\begin{array}[t]{@{} r@{ \ = \ }l}
%             \sem{\word{Player A}} 
%             & \set{Y \subseteq D : \playera \in Y} \\
%             & \set{ \set{a,b}, \set{a} }
%           \end{array}$  
%    \item\label{ex-refinements} 
%      $\Refine(\word{Player A}) = 
%      \set{
%        \begin{array}[c]{l}
%          \set{\set{a,b}, \set{a}}  \\
%          \set{\set{a,b}} \\
%          \set{\set{a}} \\
%        \end{array}
%      }$
%   \end{examples}
% \end{examples}

%=====================================================================

\subsection{Pragmatic reasoning}\label{sec:agents}

%\marginnote{This section has been substantially revised in response to the technical changes for refinement.}

Our pragmatic model combines the logical grammar of
\secref{sec:grammar} with the lexical refinements of
\secref{sec:refine}. The basic ingredients are given in
\eg{modobjects}. We take as given a context $c$, an interpreted
fragment $\tuple{\Grammar, \Domain, \Worlds, \sem{\cdot}}$ as in
\tabref{tab:grammar}, with context free grammar $\Grammar$, a domain
of entities $\Domain$, a set of worlds $\Worlds$, an interpretation
function $\sem{\cdot}$ interpreting expressions of $\Grammar$ in these
domains, and a refinement function $\Refine(\varphi)$ that is defined
for all lexical items in $\Grammar$.
%
\begin{examples}
\item\label{modobjects}
  \begin{examples}
  \item\label{messages} $\Messages$ is a subset of the
    proposition-denoting expressions generated by $\Grammar$. It is
    augmented with a null message $\nullmsg$ such that
    $\sem{\nullmsg} = \Worlds$.

  \item\label{lexset}% 
    $\LexSet = \set{\Lex' :  \Lex'(\nullmsg) = \Worlds \text{ and } \Lex'(\msg) \in \Refine(\msg)}$             
  
  \item $\StatePrior : \Worlds \mapsto [0,1]$ is a prior probability
    distribution over worlds.

  \item $\Costs : \Messages \mapsto \Reals$ is a cost function on
    messages.  For lexical items, costs are specified. For a
    nonterminal node $A$ with daughters $B_{1} \ldots B_{n}$,
    $\Costs(A) = \sum_{Y_{i}}\Costs(B_{i})$.

  \item $\LexPrior : \LexSet \mapsto [0,1]$ is a prior probability
    distribution over lexica.
  \end{examples}
\end{examples}

In this paper, we do not bias the prior distribution over states
$\StatePrior$ or the prior distribution over lexica $\LexPrior$ in any
way, assuming them to be flat. Since we do not have experimental
measurements for the priors, this seems like the safest option. (For
techniques for measuring and manipulating state priors, see
\citealt{Frank:Goodman:2012} and
\citealt{Stiller:Goodman:Frank:2011}.)  Similarly, we do not explore
different cost functions on messages, assuming them all to be $0$ for
simplicity. Our cost functions plays a role only in disfavoring the
`null message' $\nullmsg$, which is stipulated to be true in all
worlds in all lexica. This null message can be thought of as gathering
together all of the messages that are unusable in the context because
they don't make any relevant distinctions. (This message also helps to
ensure that our agents always return defined values.)

Our focus is on the space of lexica defined by
\subeg{modobjects}{lexset} given a certain set of relevant messages,
as in \subeg{modobjects}{messages}. Clause~\subeg{modobjects}{lexset}
specifies all of the possible lexica given the original interpretation
function $\sem{\cdot}$ and $\Refine$. It is the space opened up by
these constructs that allows us to predict where and how embedded
implicatures will be perceived as salient. It should be noted in this
context that our decision to refine only lexical items, as in
\subeg{modobjects}{lexset}, is made only for simplicity. We could
allow arbitrary words and phrases to be refined, as \CFS\ in effect
do.

With this background in place, we now define the core lexical
uncertainty model. It consists of three inter-related
agents:\footnote{Two notational conventions. First, $\Indicator$ is an
  indicator function, returning $1$ if its argument is true, else
  $0$. Second, $P(a \given b) \propto X$ is read `the value $P(a
  \given b)$ is proportional to the value $X$'. In this context, the
  exact value of $P(a \given b)$ can always be obtained by dividing
  $P(a \given b)$ by the sum of all the values $X'$ obtained by
  replacing $a$ by one of its $a'$.}
%
\begin{examples}
\item\label{agents}
  \begin{examples}
  \item\label{l0}%
    $\listenerZero(\state \given \msg, \Lex) \propto
    \frac{\Indicator(\state \in \Lex(\msg))}{|\Lex(\msg)|}
    \StatePrior(\state)$

  \item\label{s1}% 
    $\speakerOne(\msg \given \state, \Lex) \propto
    \exp
    \left(
      \log\listenerZero(\state \given \msg, \Lex)
      - 
      \Costs(\msg)
    \right)$
    
  \item\label{L} 
    $\UncertaintyListener(\state \given \msg) 
    \propto 
    \StatePrior(\state)
    \sum_{\Lex \in \LexSet}
    \LexPrior(\Lex)
    \speakerOne(\msg \given \state, \Lex)$
  \end{examples}
\end{examples}

The first two agents, $\listenerZero$ and $\speakerOne$, are
fixed-lexicon agents, and the final listener $\UncertaintyListener$
reasons over all of the lexica in $\LexSet$.  The most basic agent is
$\listenerZero$. It defines a conditional distribution over worlds
given messages. It does this by simply mapping the truth conditions
into a probability distribution and incorporating the state prior. So
this is just the semantics turned into a probability distribution for
the sake of decision making.

The speaker agent $\speakerOne$ is already a pragmatic agent, in the
sense that it reasons, not about the lexicon directly, but rather
about how the listener will reason about the lexicon. The logarithm
and exponentiation in this definition allow us to include real-valued
costs; where the costs are all $0$, it reduces to
$\listenerZero(\state \given \msg)$, by the identity $x =
\exp(\log(x))$.  Similarly, if the costs are scaled into $[0,1]$, then
the values can be given as a product of the listener probabilities and
the costs, analogously to the listener.

Our pragmatic listener is defined in \subeg{agents}{L}. This agent
sums over all of the inferences defined by the lexicon-specific agents
$\speakerOne$ and $\listenerZero$. It additionally incorporates the
state prior, as $\listenerZero$ does, and the prior over lexica.  This
is the agent that we use to characterize listener inferences and
define our predictions about our experimental findings.

We have given the model in its simplest form. Many elaborations are
possible. For instance, one could allow further iteration before the
lexical uncertainty listener, by defining generalized versions of
these fixed-lexicon agents that can reason about each
other. Similarly, one could allow further iteration beyond
$\UncertaintyListener$, defining speaker and listener agents
analogously to their fixed lexicon counterparts.  For exploration of
these ideas, we refer to the extended treatment in
\citealt{Bergen:Levy:Goodman:2014}. In a similar vein, one can
refactor the uncertainty listener so that it makes joint inferences
about the lexicon, the world, and perhaps other objects
\citep{Smith:Goodman:Frank:2013, Kao-etal:2014}. In addition, with
recursion allowed on both sides of the lexical-uncertainty listener,
one can push the marginalization up and down in the agent hierarchy
\citep{Goodman:Lassiter:2013}. Finally, one can include a real-valued
temperature parameter $\lambda$ in the speaker agents to control how
greedily they try to extract information from the agent they are
reasoning about, with higher $\lambda$ values leading to more
aggressive pragmatic strategies
\citep{Sutton:Barto:1998,Bergen:Levy:Goodman:2014}.

%=====================================================================

\subsection{Illustrations}\label{sec:illustrations}

Our first illustration, given in \figref{fig:simplescalar}, is
designed solely to reveal details about how the agents interact to
produce enriched meanings. We assume that the domain consists of just
one entity, $\playera$, and that the only intensional distinction of
interest is whether $\playera$ scored none of his shots (world
\world{N}), some but not all of his shots (\world{S}), or all of his
shots (\world{A}). The action is in the relationship between the two
predicates \word{scored} and \word{aced}: we define $\gsem{scored} =
\set{\tuple{\world{S}, \playera}, \tuple{\world{A}, \playera}}$ and
$\gsem{aced} = \set{\tuple{\world{A}, \playera}}$. Thus, \word{aced}
strictly entails \word{scored}, creating the potential for a scalar
implicature.

\begin{figure}[!ht]
  \[
  \setlength{\arraycolsep}{4pt}
  \begin{array}{r c c c}
    \UncertaintyListener &
    & \genericscalar{0}{\graycell{.71}}{.29}{0}{0}{\graycell{1}}{.75}{.25}{0}
    \\
    & \multicolumn{1}{r}{\swarrow}& \multicolumn{1}{c}{\downarrow}& \multicolumn{1}{l}{\searrow}
    \\
    \speakerOne
    &
    \scalarspeaker{0}{0}{\graycell{1}}{\graycell{.99}}{0}{.01}{.5}{.5}{0}
    &
    \scalarspeaker{0}{0}{\graycell{1}}{\graycell{.99}}{0}{.01}{0}{.99}{.01}
    &
    \scalarspeaker{0}{0}{\graycell{1}}{0}{0}{\graycell{1}}{.5}{.5}{0}
    \\
    & \downarrow & \downarrow & \downarrow
    \\
    \listenerZero
    &
    \genericscalar{0}{.5}{.5}{0}{0}{1}{.33}{.33}{.33}
    &
    \genericscalar{0}{1}{0}{0}{0}{1}{.33}{.33}{.33}
    &
    \genericscalar{0}{0}{1}{0}{0}{1}{.33}{.33}{.33}
    \\
    & \downarrow & \downarrow & \downarrow 
    \\    
    \Messages
    &
    \genericscalar{\False}{\True}{\True}{\False}{\False}{\True}{\True}{\True}{\True}
    &
    \genericscalar{\False}{\True}{\False}{\False}{\False}{\True}{\True}{\True}{\True}
    &
    \genericscalar{\False}{\False}{\True}{\False}{\False}{\True}{\True}{\True}{\True}
    \\
    & \uparrow & \uparrow & \uparrow 
    \\                               
    \Lex
    & 
    \scalarlex{\tuple{\world{S},\playera}, \tuple{\world{A},\playera}}
    & 
    \scalarlex{\tuple{\world{S},\playera}}
    &
    \scalarlex{\tuple{\world{A},\playera}}   
  \end{array}
  \]
  \caption{Simple scalar inference. 
    We assume a flat prior over states and lexica. 
    $\Costs(\nullmsg) = 5$, and $\Costs(\msg) = 0$ for the other messages. 
    The uncertainty listener $\UncertaintyListener$ infers that the general term 
    \word{scored} excludes its specific counterpart \word{aced} in this context.}
  \label{fig:simplescalar}
\end{figure}

To keep the example compact, we let
$\Refine(\word{Player A}) = \set{\sem{\word{Player A}}}$. Since
\word{aced} already denotes a singleton set, it has no space for
further refinement. However, \word{scored} has two further
refinements. This gives rise to the three lexica in the bottom row of
\figref{fig:simplescalar}. The literal listener $\listenerZero$ turns
these lexica into conditional distributions over states given
messages.  The prior over states is flat in this example, so this
calculation just evenly divides the probability mass over the true
states. The pragmatic speaker responds to this agent. 
%%%% Woops, this isn't true for s1! ---CP
% Already at this stage, we can see Gricean behavior: where possible,
% the speaker avoids an ambiguity inherent in the original lexicon by
% saying \word{Player A aced} in \world{A} even though \word{Player A
% scored} is also true there. The rightmost lexicon does not support
% this pragmatic behavior, but the others do.
Finally, our uncertainty listener sums over these three speakers,
achieving a scalar implicature: hearing \word{Player~A scored} leads
this listener to assume that the state is \world{S}.

Lexical uncertainty is not required to achieve this result. If we
allow no meanings to be refined, then we deal with the singleton set
of lexica containing only the leftmost lexicon. In this small space,
the model is effectively equivalent to the rational speech act model of
\citet{Frank:Goodman:2012} (with potentially small differences
relating to how the prior over states is incorporated), and it is also
a more thoroughly probabilistic version of the iterated best response
model \citep{Franke09DISS,Jaeger:2007,Jaeger:2011}. Nonetheless, the
example illuminates how the lexical uncertainty model works. As the
downward arrows indicate, it is useful to start conceptually from
$\UncertaintyListener$. This agent effectively reasons in Gricean
terms about three separate lexica; the alternation from speaker to
listener and down to the lexicon mirrors the nested belief structure
of Grice's original definition of implicature (sketched at the start
of \secref{sec:implicature}).

Even though we assume an even prior over lexica, useful biases emerge
because the space of lexica is structured: there are no lexica in
which \word{aced} is consistent with \world{S}, but there are two in
which \word{scored} is. This bias carries through the computation to
create a strong final bias for the implicature inference. For further
discussion of this important point, we refer to
\citet{Bergen:Levy:Goodman:2014}, where it is shown to be essential to
generating implicatures based on the principle that marked forms
signal marked meanings and unmarked forms signal unmarked meanings
\citep{McCawley78,Horn84,Blutner98,Levinson00}.

%\marginnote{This example reframed around the two different approaches to refinement.}

Let's now look at a larger and more complex signaling game, one that
starts to show the potential of this model to predict embedded
implicatures. In this scenario, there are two players. We continue our
convention of referring to worlds using sequences like \world{NN}
(`neither player scored'). The lexical items are \word{Player A},
\word{Player B}, \word{some}, \word{every}, \word{no}, \word{scored},
and \word{aced}.  To start, we assume that, for all lexical items
$\varphi$, $\Refine(\varphi) = \wp(\sem{\varphi}){-}\emptyset$.  This
creates an enormous space of lexica, and allows the full range of
possible interactions between the refinements. 

The listener inferences are summarized in \tabref{tab:subjects}. For
the most part, they seem aligned with the general view in the
literature about how scalar terms interact in contexts like this. For
instance, we predict that a proper name \word{P} will take on the
exhaustified sense \word{only P}, as we would expect given the
salience of \word{every}. In turn, \word{some} is interpreted as
non-specific in virtue of the salience of the two names, and it also
leads to a scalar implicature due to the salience of
\word{every}. Perhaps the most striking outcome is that the scalar
inference from \word{scored} to not-aced remains in evidence not just
with the proper names but also in the scope of the quantified
subjects: the best-guess inference for \word{every player scored} is
\world{SS}, and the best-guess inferences for \word{some player aced}
are \world{NA} and \world{AN}. These effects derive from interacting
lexical uncertainty between the subjects and predicates.

\Tabref{tab:subjects} reveals some drawbacks to unfettered exploration
of refinements, however. First, we might expect hearing \word{some
  player scored} to lead the listener to assume that the state was
either \world{NS} or \world{SN}, corresponding to enrichment of both
the subject (`not all players') and the predicate (`merely
scored'). The current model does not achieve this. In addition, the
row for \word{no player scored} is unintuitive. The best inference is
\world{NN}, which is in line with the literal semantics, but it is
striking that the states \world{NS} and \world{SN} have some positive
probability. This arises because of interacting lexical uncertainty:
there are lexica in the space in which \word{scored} is refined to
exclude one of the players. In that case, the negative universal turns
out to be true. Only a few lexica support this interaction, ensuring
that it cannot become dominant, but it still seems worrisome.

It's a bit perverse to assume, as we did in this example, that lexical
items can be enriched in arbitrary ways. We take it to be one of the
major lessons of neo-Gricean approaches that alternatives are
contextually and lexically constrained. \CFS's treatment of $\OALT$
reflects this insight, and our own handling of refinement and lexical
uncertainty allows us to incorporate it as well. So it is worth seeing
whether we can improve the picture in \tabref{tab:subjects} by further
specify that the following set of refinements, which basically encode
lexical scales that we might specify for these items:
%
\begin{examples}
\item\label{neo}
  \begin{examples}
  \item $\Refine(\word{Player A}) = \set{\sem{\word{Player A}}, \sem{\word{only Player A}}}$
  \item $\Refine(\word{Player B}) = \set{\sem{\word{Player B}}, \sem{\word{only Player B}}}$
  \item $\Refine(\word{some}) = \set{\sem{\word{some}}, \sem{\word{some and not all}}}$
  \item $\Refine(\word{no}) = \set{\sem{\word{no}}}$    
  \item $\Refine(\word{scored}) = \set{\sem{\word{scored}}, \sem{\word{scored and didn't ace}}}$
  \item $\Refine(\word{aced}) = \set{\sem{\word{aced}}}$
  \end{examples}
\end{examples}
%
The results of working in this more refined refinement space are given
in \tabref{tab:subjects-ALTstyle}. The picture is mostly unchanged,
except we now also achieve the target enrichment for \word{some player
  scored}, and the messiness surrounding \word{no player scored} is
fully addressed. The only worry one might have about
\tabref{tab:subjects-ALTstyle} is that it predicts rather aggressive
pragmatic enrichment of the scalar term in the scope of the negative
quantifier. It has long been assumed that scalar items in such
environments fail to give rise to implicatures, presumably because the
negative environment makes weak scalar items strong and thus leaves
them less space for enrichment
\citep{Levinson00}. \citet{Chemla:Spector:2011} address this question
experimentally, finding low but non-negligible rates of local
enrichment in negative environments. We too treat this as an
experimental question; in \secref{sec:exp1}, we find evidence that
local enrichment of this sort are indeed salient possibilities for
humans.

This completes our overview of the compositional lexical uncertainty
model. We now to turn to our human subjects experiments, where we show
both that embedded implicatures seem to be real and that the above
model achieves excellent fits with human judgment patterns for such
sentences.

\begin{table}[t]
  \centering
  \setlength{\tabcolsep}{4pt}
  %
  % Lexica: 2,086,465
  %
  \begin{tabular}[c]{r *{9}{r} }
    \toprule
    & \world{NN} & \world{NS} & \world{NA} & \world{SN} & \world{SS} & \world{SA} & \world{AN} & \world{AS} & \world{AA}\\
    \midrule
    \word{Player A scored} & 0.0 & 0.0 & 0.0 & \graycell{0.24} & 0.19 & 0.16 & 0.18 & 0.16 & 0.07\\
    \word{Player A aced} & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & \graycell{0.36} & 0.3 & 0.34\\
    \word{Player B scored} & 0.0 & \graycell{0.24} & 0.18 & 0.0 & 0.19 & 0.16 & 0.0 & 0.16 & 0.07\\
    \word{Player B aced} & 0.0 & 0.0 & \graycell{0.36} & 0.0 & 0.0 & 0.3 & 0.0 & 0.0 & 0.34\\
    \word{some player scored} & 0.0 & 0.14 & 0.11 & 0.14 & \graycell{0.17} & 0.14 & 0.11 & 0.14 & 0.05\\
    \word{some player aced} & 0.0 & 0.0 & \graycell{0.22} & 0.0 & 0.0 & 0.19 & \graycell{0.22} & 0.19 & 0.18\\
    \word{every player scored} & 0.0 & 0.0 & 0.0 & 0.0 & \graycell{0.31} & 0.27 & 0.0 & 0.27 & 0.14\\
    \word{every player aced} & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & \graycell{1.0}\\
    \word{no player scored} & \graycell{0.31} & 0.14 & 0.12 & 0.14 & 0.06 & 0.05 & 0.12 & 0.05 & 0.01\\
    \word{no player aced} & 0.18 & \graycell{0.19} & 0.08 & \graycell{0.19} & 0.14 & 0.06 & 0.08 & 0.06 & 0.0\\
    $\nullmsg$ & 0.01 & 0.01 & \graycell{0.32} & 0.01 & 0.01 & 0.15 & \graycell{0.32} & 0.15 & 0.0\\
    \bottomrule
  \end{tabular}
  \caption{Enrichment in the largest space of
    refinements supported by this lexicon.}
  \label{tab:subjects}
\end{table}

\begin{table}[t]
  \centering
  \setlength{\tabcolsep}{4pt}
  %
  % Lexica: 476
  %
  \begin{tabular}[c]{r *{9}{r} }
  \toprule
    & \world{NN} & \world{NS} & \world{NA} & \world{SN} & \world{SS} & \world{SA} & \world{AN} & \world{AS} & \world{AA}\\
    \midrule
    \word{Player A scored} & 0.0 & 0.0 & 0.0 & \graycell{0.45} & 0.11 & 0.22 & 0.15 & 0.05 & 0.02\\
    \word{Player A aced} & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & \graycell{0.42} & 0.36 & 0.22\\
    \word{Player B scored} & 0.0 & \graycell{0.45} & 0.15 & 0.0 & 0.11 & 0.05 & 0.0 & 0.22 & 0.02\\
    \word{Player B aced} & 0.0 & 0.0 & \graycell{0.42} & 0.0 & 0.0 & 0.36 & 0.0 & 0.0 & 0.22\\
    \word{some player scored} & 0.0 & \graycell{0.25} & 0.09 & \graycell{0.25} & 0.06 & 0.12 & 0.09 & 0.12 & 0.01\\
    \word{some player aced} & 0.0 & 0.0 & \graycell{0.24} & 0.0 & 0.0 & 0.21 & \graycell{0.24} & 0.21 & 0.11\\
    \word{every player scored} & 0.0 & 0.0 & 0.0 & 0.0 & \graycell{0.61} & 0.16 & 0.0 & 0.16 & 0.07\\
    \word{every player aced} & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & \graycell{1.0}\\
    \word{no player scored} & \graycell{0.61} & 0.0 & 0.16 & 0.0 & 0.0 & 0.0 & 0.16 & 0.0 & 0.06\\
    \word{no player aced} & \graycell{0.19} & 0.17 & 0.1 & 0.17 & 0.13 & 0.07 & 0.1 & 0.07 & 0.0\\
    $\nullmsg$ & \graycell{0.15} & 0.13 & 0.13 & 0.13 & 0.1 & 0.09 & 0.13 & 0.09 & 0.05\\
    \bottomrule
  \end{tabular}
  \caption{Enrichment using the lexically-driven
    (neo-Gricean) refinements sets in \eg{neo}.}
  \label{tab:subjects-ALTstyle}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Experiment: Scalars under quantifiers}\label{sec:exp1}

% \marginnote{Tried to give a slightly more ``APA''-ish writeup to the
%   study so that experimental methods are a bit more transparent, while
%   maintaining the useful justification from previous draft.}

With our experiment, we sought to obtain a clearer picture of the
availability of enriched inferences for scalar terms embedded below
quantifiers. We told participants that they were helping to train an
automated sportscasting system and asked them to make judgements about
sentences in the contexts of displays like \figref{fig:exp1}.  This
cover story was designed to ensure that implicatures are relevant,
that is, worth calculating where available
(\seccitealt{Chemla:Spector:2011}{3.1};
\citealt{Clifton:Dube:2010}). Our goal was to better understand the
extent to which certain pragmatic inferences are available, so we
sought out a scenario that would be maximally favorable to
implicatures.\footnote{For studies aimed at understanding the
  prevalence of implicatures, see
  \citealt{Paris:1973,Hendriks-etal:2009}.}

Our design builds directly on previous studies by
\citet{Geurts:Pouscoulous:2009} and \citet{Chemla:Spector:2011}, and
there is an obvious correspondence between their geometric shapes and
our tournament displays. However, our experiment is not a simple
reproduction of theirs. Three major differences are worth
highlighting. First, previous experiments in this area have used
abstract geometric displays. Together with the inevitable complexity
of the sentences involved, this seems likely to be cognitively
demanding in ways that could affect the stability and reliability of
the responses (for discussion, see \citealt{Clifton:Dube:2010}). Our
more naturalistic displays arguably place fewer cognitive demands on
participants, allowing them to concentrate on how well the sentences
identify the world.  Second, \citeauthor{Chemla:Spector:2011} use
wheel-like displays in which lines extend from the vertex to the
perimeter. There are potentially many ways this state can be drawn,
and some might be more iconic than others. With our displays, it was
computationally straightforward to show participants every relevant
variant of the condition, which allowed us to factor out this kind of
variation in our analyses.  Third, \citeauthor{Chemla:Spector:2011}
used a within-subjects design: the individual participants judged
every sentence in every context. This means that subjects could draw
comparisons across different conditions, which creates opportunities
for them to register comparative judgments involving the experimental
contexts itself, rather than relying solely on their linguistic
intuitions. We hypothesized that a between-subjects design would avoid
these potential complications.

%=====================================================================

\subsection{Methods}

\subsubsection{Participants}

The experiment had 300 participants, all recruited with Amazon's
Mechanical Turk. No participants or responses were excluded.

\subsubsection{Materials}

\begin{figure}[t]
  \centering
  \framebox{\includegraphics[scale=1]{fig/experiment-display}}
  \caption{Experiment display.}
  \label{fig:exp1}
\end{figure}


We generated displays like those in \figref{fig:exp1}. In each
display, each of the three players, A, B, and C, has taken 12 basketball shots (a number
small enough for visual display but outside of the subitizing range
and thus less likely to introduce competitions from cardinal
determiners like \word{three shots};
\citealt{Degen:Tanenhaus:2014}). The shots were divided into two
piles, labeled `baskets' (green) and `misses' (red). 

Target sentences describing the displays were defined as follows:
%
\begin{examples}
\item\label{expmsgs} 
  \begin{tabbing}    
    \phantom{Exactly one} \= \phantom{player hit some} \= \kill
    Every \> player hit  all \> of his shots.\\
    Every \> player hit none \> of his shots.\\
    Every \> player hit some \> of his shots.\\    
    Exactly one \> player hit all \> of his shots.\\
    Exactly one \> player hit none \> of his shots.\\
    Exactly one \> player hit some \> of his shots.\\
    No \> player hit all \> of his shots.\\
    No \> player hit none \> of his shots.\\
    No \> player hit some \> of his shots.
  \end{tabbing}
 % $\set{
 %      \text{$Q$ player hit his $S$ of his shots} :
 %      \begin{array}{l}        
 %        Q \in \set{\text{exactly one}, \text{every}, \text{no}}, \\
 %        S \in \set{\text{all}, \text{none}, \text{some}}
 %      \end{array}}$
\end{examples}
%
Following previous studies, we put a bound pronoun in the embedded
quantifier to try to ensure that the subject took scope over the
object. The partitive forms seem likely to further encourage
implicature calculation \citep{Grodner-etal:2010}. We chose the verb
\word{hit} over the slightly less marked verb \word{make} to try to
avoid the sense of `make' as in `take' (consistent with missing).

For the target items, there were nine different conditions,
corresponding to the worlds in \eg{conds}, in the notation we've been
using to identify possible worlds.
%
\begin{examples}
\item\label{conds} $\set{\world{NNN}, \world{NNS}, \world{NNA},
    \world{NSS}, \world{NSA}, \world{NAA}, \world{SSS}, \world{SSA},
    \world{SAA}, \world{AAA}}$
\end{examples}
%
%\todo{Dan might check this paragraph to make sure the details align with the set-up he created.}
%
This is a subset of the full cross-product of the three outcomes
\world{N}, \world{S}, and \world{A} in which player $i$ always did at
least as well as player $i+1$, going left to right.  Our target
sentences are all quantified, so we don't care about the outcome for
any single player, meaning that we don't distinguish, e.g.,
\world{NNS} from \world{NSN}, allowing us to work with this smaller
set of conditions. In the experiment, the `order' of each world was
randomized, so that, e.g., \world{NSA} appeared visually in all three
of its orders.  

% \marginnote{This is the paragraph justifying our experiment as more than a reproduction. We could tr to be more hard-hitting, but my heart isn't in it --- C\&S did a great job too.}



\subsubsection{Procedure} 

After reading our consent form, participants were given the following
cover story:

\begin{quote}
  We are trying to train an automated sportscasting system to generate
  color commentary on simple competitions. We'd like you to make
  judgments about the quality of the comments it generates. We'll use
  these ratings to train our system further.
\end{quote}

After reading the cover story and some instructions, participants were
presented with three training items, designed to ensure that participants
understood the cover story, displays, and sentences. They then judged 32
sentences, divided into nine target sentences and 23 fillers. The
design was between-subjects: no experimental participant judged the same sentence twice. 
 
Each sentence received a
total of 300 responses. For the target sentences, each sentence--world
pair received between 19 and 44 responses (mean 30); this variation
resulted from randomization of the assignment of worlds to sentences. 

Target sentences were presented below displays. Participants were
asked to evaluate sentences on a seven-point
Likert scale ranging from `Bad description' to `Good description'. Our
rationale for using this scale is that it allows enough space for
participants to both register a truth-value assessment and convey
information about the quality of the report. (In this sense, our
participants acted as listeners who got to observe the speaker's state
and assess the extent to which the speaker succeeded in conveying that
state with her utterance.)

All the materials and response data for the experiment are available at
the website for this paper.

%=====================================================================

\subsection{Results}\label{sec:exp1:results}

% \todo{Does this section need to do some stats testing of pairwise differences? If so, I suppose I would do Mann-Whitney U test (not all the items have the same number of responses), but I am open to alternatives. All the differences we care about are numerically large, though.}

\Figref{fig:exp1-results} summarizes the responses by target sentence
and the world in which it was evaluated. Overall, participants made judgments that accurately reflected whether sentences were true or false; accuracy was
especially clear for the sentences in the first two columns, which do
not admit pragmatic enrichment. For these cases, the average ratings are not
statistically different from 1 (the lowest value) where the sentence
is false, and the ratings average above 6 (the second highest value)
where the sentence is true. The pattern of judgments in these
conditions thus suggests that our method is appropriate for measuring
participants' interpretations.\footnote{The only exception to this general pattern is the sentence \word{No player hit
  none of his shots} (bottom middle), which received lower than normal
ratings in all its true conditions and relatively high ratings for
\world{NNN}, where it is false on its literal construal. We
hypothesize that this pattern of date reflects a
negative concord construal, on which the embedded term is interpreted
as equivalent to \word{any of his shots}, creating a meaning that is
true only in \world{NNN}. Negative concord of this sort is productive
in many dialects of English and understandable in all or nearly all of
them. This likely created uncertainty about the intended meaning of
the sentence, leading participants to disfavor it in general.}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.85\textwidth]{fig/basketball-pilot-2-11-14-results-parsed}
  \caption{Mean ratings by sentence with bootstrapped 95\% confidence intervals.}
  \label{fig:exp1-results}
\end{figure}


Turning to the critical conditions, responses for 
\target{every}{some} (upper right) were
strongly indicative of local enrichment. This sentence received its
highest ratings in the \world{SSS} world. As we reviewed in
\secref{sec:implicature}, example \eg{everysome-sem}, in order to
count as a complete report in this world, this sentence requires
either local enrichment or a Gricean calculation with auxiliary
premises. Worlds \world{SSA} and \world{SAA} received the next highest
average ratings. Only a simple Gricean calculation is required for the
sentence to completely describe this condition. The
\world{AAA} world received significantly lower ratings than the
others, which probably reflects the pragmatic fact that the salient
alternative \word{every player hit all of his shots} is a more
complete description.

Nevertheless, \target{every}{some} is not a strong test of the
presence of local readings, since the entailment relations between the readings
introduce some indeterminacy into the analysis. In particular, since
the local enrichment entails the literal reading, we can't be sure
whether the high ratings for \world{SSS} derive entirely from the
availability of a local enrichment: a literal construal would
suffice to make the sentence true. However, as we discussed in
\secref{sec:implicature}, \citeauthor{Chemla:Spector:2011} show that
\target{every}{some} is of limited utility in distinguishing
theoretical proposals anyway. It is the \target{exactly one}{some}
sentence that allows us to probe most confidently for local
readings. 

The response pattern for the critical item \target{exactly one}{some} is given in the
middle right of \figref{fig:exp1-results}. The highest ratings are in
the \world{NNS} condition, where it is true under its literal and
local enrichment construals. However, it also received high ratings in
the \world{NSA} and \world{SAA} worlds, where it is true only with
local enrichment (because two players hit at least some of their
baskets in these worlds, ruling out the literal construal).  We note
also that its more strictly truth-conditional interpretation seems to
be salient as well, as it was rated highly on average in the
\world{NNA} condition.

Finally, the pattern for \target{no}{some} also suggests a non-trivial
amount of local enrichment: though \world{NNN} received the highest
average ratings, indicating a preference for a literal construal, the
ratings for \world{NNA}, \world{NAA}, and \world{AAA} are fairly high
(though with wide confidence intervals). These are the worlds in which
no player hit only some of his shots, the local enrichment. This
finding seems consistent with the low but non-negligible rates of
local enrichment that \seccitet{Chemla:Spector:2011}{4.4.4} report for
this quantifier pair. One qualification we should add here is that our
sentence is arguably somewhat unnatural in that it places \word{some},
a positive polarity item \citep{Baker70,Israel96}, in the scope of a
negative quantifier. The binding relation between the subject and the
pronoun \word{his} in the embedded phrase should force a surface-scope
reading, but we can't rule out the possibility that participants might
have found an inverse-scope construal (`some shots are such that no
player hit them') that took the scalar term out of the scope of the
negation.

We conclude from these response patterns that local enrichment is
possible even in non-monotone environments (replicating
\citet{Chemla:Spector:2011}), and that local enrichment might be
available in downward monotone environments as well. However, our
concern is not only whether such readings are possible or
impossible, but rather how accurately we can predict
their availability on the basis of contextual and world knowledge. 
% In this way, our objectives are more closely aligned with Griceans like
% \citet{Geurts09}, \citet{Geurts:Pouscoulous:2009}, and
% \citet{geurts-vantiel:2013:scalar}. 
We turn now to the task of
assessing the ability of the model in \secref{sec:model} to match
both the quantitative and qualitative patterns in this experimental
data.

%=====================================================================

\subsection{Model assessment}

% \marginnote{CP: This section has been totally reconceived and rewritten.}

% \marginnote{MCF: slight changes to the model justification, in
%   particular, cutting down NHST justification.}

The pattern of data we observed is sufficiently precise and detailed
that arbitrary statistical comparisons with a null hypothesis are
not informative. Instead, to characterize the patterns of inference
that give rise to the observed data, we use a model-comparison
approach. In particular, we evaluate four related
models that each embody different characterizations of linguistic
meaning. By comparing these models, we can gain insights into the
aspects of each that contribute to particular patterns of predictions.


%  The rationale for this approach is
% that a more standard regime of assessing correlations with the
% experimental responses against the null hypothesis of statistical
% independence is not illuminating: as we have seen, our human response
% patterns are broadly in agreement with the intuitions that guided the
% development of these models, so we can take it for granted that these
% correlations are high. And, indeed, all the models considered here
% achieve significant correlations at $p < 0.001$, for just about any
% measure of correlation one chooses.  We know already that the null
% hypotheses given by frequentist statistical tests are false, so we
% pursue a strategy that is more stringent and more likely to provide
% insights into the quality of the underlying model.

For all the models, we take as given the literal semantics described
in \tabref{tab:grammar}, as well as the following features of the
context:
%
\begin{examples}
\item\label{expmod}
  \begin{examples}
  \item $\Domain = \set{\playera, \playerb, \playerc}$
  \item $\Worlds = $ the set in \eg{conds}
  \item\label{expformulae} $\Messages =
    \setlength{\arraycolsep}{2pt}
    \set{
      Q(\word{player})(\word{hit}(S\negthinspace(\word{shot}))) :
      \begin{array}{l}        
        Q \in \set{\word{exactly one}, \word{every}, \word{no}}, \\
        S \in \set{\word{every}, \word{no}, \word{some}}
      \end{array}}$
  \item $\Costs(\nullmsg) = 5$; $\Costs(\msg) = 0$ for all $\msg \in \Messages{-}\set{\nullmsg}$  
  \item Flat state prior: $\StatePrior(w) = \StatePrior(w')$ for all $w, w' \in \Worlds$
  \item Flat lexicon prior: $\LexPrior(\Lex) = \LexPrior(\Lex')$ for all $\Lex, \Lex' \in \LexSet$
  \end{examples}
\end{examples}

The domain $\Domain$ and worlds $\Worlds$ come directly from our human
experiment. Similarly, the set of messages $\Messages$ corresponds to
\eg{expmsgs}, with some adjustments to keep the logical grammar
simple. We stipulate flat priors and even costs (other than the empty message). As noted in
\secref{sec:model}, we do not have empirical estimates for these
values; though better fits to the human data can be achieved by adding
assumptions about them, this risks overfitting to the data we have and
thus overstating the true accuracy of the models.

The models we consider are defined as follows:
%
\begin{examples}
\item 
  \begin{examples}
  \item \tech{Literal semantics}: the predicted values are the output
    of $\listenerZero$, as in \subeg{agents}{l0}, run on the messages
    defined in \subeg{expmod}{expformulae}.
  \item \tech{Fixed-lexicon pragmatics}: the predicted values are the
    output of \subeg{agents}{L}, but all the lexical items have only
    themselves as refinements, so that the reasoning is entirely in
    terms of the base lexicon in \tabref{tab:grammar}.
  \item \tech{Unconstrained refinement}: the inferences of the
    uncertainty listener \subeg{agents}{L} with $\Refine(\word{some})
    = \wp(\sem{\word{some}}){-}\emptyset$
  \item \tech{Neo-Gricean refinement}: as in `Unconstrained
    refinement', but with $\Refine(\word{some}) =
    \set{\sem{\word{some}}, \sem{\word{some and not all}}}$.
  \end{examples}
\end{examples}

These models represent a broad range of approaches to linguistic
meaning. The first neglects pragmatics entirely (the model includes a
contextual prior over states, but we define it as flat). The second is
equivalent to the rational speech acts (RSA) model of
\citet{Frank:Goodman:2012} and \citet{Goodman:Stuhlmuller:2013}
(perhaps with minor differences concerning how priors are
incorporated). RSA has been shown to capture a broad range of scalar
implicatures, but it is known to be limited in its ability to derive
manner implicatures and certain classes of embedded implicature
\citep{Bergen:Goodman:Levy:2012,Bergen:Levy:Goodman:2014}. The final
two models are full versions of the one we presented in
\secref{sec:model}. They represent opposite ends of the spectrum of
non-trivial refinements. We saw in connection with
\tabref{tab:subjects} and \tabref{tab:subjects-ALTstyle} that there
might be empirical value in greatly constraining the space of
refinements.

% \todo{Perhaps rewrite with deeper thoughts on why we chose these three measures.}

We employ three methods of comparison: Pearson's correlation
coefficient, which measures the linear correlation between the human
responses and the model predictions; Spearman's rank correlation
coefficient, which assesses how closely the human responses and model
responses are aligned in terms of the rankings they predict; and the
mean-squared error (MSE) of the model predictions as compared with the
human responses, which summarizes the distance of the predictions
from the human behavior. The use of these three measures allows us to
detect models that reproduce quantitative correspondence (Pearson
correlation), qualitative correspondence (Spearman correlation), and absolute
fit between models and data.

% \marginnote{This paragraph defines the linking hypothesis.}

Our model predictions are conditional probability distributions over
states given messages, and hence constrained to be in the range
$[0,1]$ and to sum to $1$. In contrast, our human responses are Likert
values in $\{1,2,3,4,5,6,7\}$ with no constraint that they sum to
any particular value. To align these values, we rescale the human responses: if $x^{s}$
is the $10$-dimensional vector of mean human responses for target
sentence $s$, then each $p^{s}$ is the vector of normalized values for
that sentence, defined so that
$p^{s}_{i} = (x^{S}_{i}-1)/\sum_{j=1}^{10}(x^{S}_{j}-1)$. This simply
normalizes the Likert responses into a probability distribution; we
subtract $1$ because the lowest Likert value is $1$. The one
noteworthy thing about this calculation is that, because it is done on
a per-sentence basis, it is not a simple linear rescaling, and so it
affects all of our assessment metrics when applied to multiple
sentences at once. However, we regard it as the minimal viable
hypothesis linking our model with our experimental data.

\begin{figure}[!h]
  \centering
  \includegraphics[height=0.92\textheight]{fig/allmodels}
  \caption{Analysis by target sentence, comparing model predictions
    with human responses.}
  \label{fig:exp-analysis}
\end{figure}

\begin{table}[th!]
  \centering
  \begin{tabular}[c]{r c c c}
    \toprule
    & Pearson & Spearman & MSE \\
    \midrule
    Literal semantics         & 0.94 & 0.76 & 0.0079\\
    Fixed-lexicon pragmatics  & 0.92 & 0.75 & 0.0094\\
    Unconstrained uncertainty & 0.93 & 0.79 & 0.0052\\
    Neo-Gricean uncertainty   & 0.95 & 0.80 & 0.0046\\
    \bottomrule   
  \end{tabular}
  \caption{Overall assessment.}
  \label{tab:overall}
\end{table}

\Figref{fig:exp-analysis} summarizes the models' predictions alongside
the human responses. The predicted values are largely aligned for the
examples without \word{some} in the object position. Where \word{some}
occurs embedded, the models diverge in qualitative terms. For
\target{every}{some}, the patterns are broadly similar, but only
`Neo-Gricean uncertainty' is able to mirror the preference ordering of
responses seen in the human data. For \target{exactly one}{some}, only
the two uncertainty models are able to predict local enrichment, in
that only they assign high probability to the crucial worlds that are
false on the literal construal: \world{NSA} and \world{SAA}. The
`Literal semantics' and `Fixed lexicon pragmatics' models are unable
to predict the salience of these construals. Similarly, only the two
uncertainty models predict \target{none}{some} to have embedded
enrichments leading to acceptability for \world{NNA}, \world{NAA}, and
\world{AAA}.

%\todo{Should we worry that the differences between correlations are not typically statistically significant?}

\Tabref{tab:overall} summarizes our overall quantitative
assessment. All of the correlations are extremely high, and the MSE
values are extremely low. This is reassuring about the general utility
of all of these models for predicting human judgments. Comparing the
values is arguably more illuminating. A few patterns stand out.
First, `Fixed-lexicon pragmatics' performs the least well overall.
Since it has been shown to add substantial value in other areas of
language and cognition, we conclude that its particular approach to
enrichment is at odds with the patterns for embedded implicatures.
The precise causes are hard to pin-point, but the fact that our target
implicatures are not always enrichments of the literal content is
surely part of the problem.  Second, while `Unconstrained uncertainty'
is better than literal semantics by the Spearman and MSE metrics, it
falls behind it on the Pearson metric. We saw in connection with
\tabref{tab:subjects} that the unintuitive lexica that this model
entertains can lead to implausible final patterns. We conjecture that
this is the root cause of the model's poor performance here as well.
Third, neo-Gricean uncertainty achieves the best results across all
three of our measures. Here again, this is consistent with our
expectations based on the large illustrative example from
\secref{sec:illustrations}, where we saw that this constrained,
lexically-driven approach to choosing refinements resulted in the best
quantitative and qualitative pattern.

The overall analysis given in \tabref{tab:overall} understates the
value of both uncertainty models when it comes to the distribution of
embedded implicatures. Our target sentences provide relatively little
space for pragmatic enrichment; in \figref{fig:exp1-results}, the left
and middle columns essentially have only literal interpretations,
leaving just the right column for our pragmatic models to
shine. What's more, our qualitative review of
\figref{fig:exp-analysis} suggests that the right column examples
reveal major distinctions. It's thus worth assessing them
quantitatively in isolation. The results of such an assessment are in
\tabref{tab:crucial-items}.  The most dramatic pattern is that the two
fixed-lexicon models are unable to capture the patterns for embedded
implicatures in the non-monotone and downward monotone
environments. In contrast, both uncertainty models capture the
patterns. These tight fits are evident in \figref{fig:exp-analysis},
and it is reassuring to see them reflected in our assessment measures.

It is also striking that the literal model is competitive for
\target{every}{some}. This probably traces to the experimentally
inconvenient fact that the enriched meaning entails the literal one,
making a literal semantics a generally safe bet. It should be noted
also that the Spearman coefficient best reflects the ability of a
model to capture the preference ordering in the human data, so the
`Neo-Gricean uncertainty' model might still be the favored choice for
this case.

Finally, it seems that neither uncertainty model is clearly superior
to the other for these data.  This suggests to us that we have not yet
found precisely the right approach to refinements (alternatives). It
is tempting to try additional refinement sets to try to find a single
model that wins decisively for all the target examples. We are wary of
doing this because, as noted above, it runs the risk of overfitting to
our experimental responses; we could easily engineer our own success.
However, this is nonetheless a fruitful avenue for future exploration
if paired with additional experiments for further validation.

\begin{table}[t]
  \centering
  \setlength{\tabcolsep}{3pt}
  \begin{tabular}[c]{r *{3}{r}@{\hspace{20pt}}*{3}{r}@{\hspace{20pt}}*{3}{r} }
    \toprule
    & 
    \multicolumn{3}{c}{\target{every}{some}} & 
    \multicolumn{3}{c}{\target{exactly one}{some}} &
    \multicolumn{3}{c}{\target{no}{some}} \\
    & 
    P & S & MSE & 
    P & S & MSE & 
    P & S & MSE \\
    \midrule  
    Literal       & \graycell{.98} &            .85 & \graycell{.00076} &            .77 &            .70 &            .01900 & \graycell{.91} &            .52 &            .03400 \\
    Fixed-lexicon &            .93 &            .87 &            .00250 &            .79 &            .70 &            .01800 &            .91 &            .52 &            .03400 \\
    Unconstrained &            .91 &            .85 &            .00350 & \graycell{.97} & \graycell{.92} & \graycell{.00096} &            .74 &            .49 &            .00890 \\
    Neo-Gricean   &            .88 & \graycell{.89} &            .00660 &            .96 &            .89 &            .00290 &            .89 & \graycell{.88} & \graycell{.00420} \\
    \bottomrule
  \end{tabular}
  \caption{Results on crucial items. `P' = `Pearson'; `S' = `Spearman'.}
  \label{tab:crucial-items}
\end{table}

Our model's performance is sensitive to the space of competitor
messages, so it is worth asking how robust these findings are to
changes in this area. We have found that the basic pattern is robust
to a number of changes to the space of quantifiers, and we invite
readers to further explore the space using our implementation.  The
only noteworthy finding we have to report in this regard is that
allowing \word{exactly one} into object position has a major impact:
while \world{SSS} remains the best-guess inference for the message
\target{every}{some} in this setting, \target{exactly one}{some} and
\target{no}{some} effectively lose their embedded implicature
readings.  This makes intuitive sense given the nature of the model:
if the speaker has the option to choose \word{exactly one of his
  shots}, and that form is equally costly, then surely her avoidance
of that form in favor of \word{some of his shots} is a signal that she
regards the local enrichment as infelicitous.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}\label{sec:conclusion}

%\marginnote{This section has been lightly revised to reflect our newer insights.}

With this paper, we sought a synthesis between Gricean accounts of
pragmatic reasoning and grammar-driven ones like that of
\citet{ChierchiaFoxSpector08}. It seems to us inevitable that both
grammar and interaction will play leading roles in the final theory of
these phenomena; at some level, all participants in the debate
acknowledge this. Our achievement is to unify the crucial components
of these approaches in a single formal model that makes quantitative
predictions.

The key components of the model are lexical uncertainty and recursive
modeling of speaker and listener agents. The lexical uncertainty
property is in evidence in \citeauthor{ChierchiaFoxSpector08}'s
account as well, in the form of underspecified logical forms with
context dependent meanings. Our model has similar formal mechanisms
but offers an account of how discourse participants reason under this
persistent linguistic uncertainty. This leads to an important
conceptual point: not all underspecification has to be resolved in
order for robust pragmatic enrichment to take place.

The recursive reasoning of our model is characteristic of both Gricean
approaches and signaling systems approaches; our model shares formal
properties of both but makes quantitative predictions of the sort that
can be correlated with human preferences in communication. There are
by now many models in the same family as ours (see, e.g.,
\citealt{CamererHo:2004,Jaeger:2011,Smith:Goodman:Frank:2013,Kao-etal:2014}),
so further exploration is likely to yield an even more nuanced
picture.

In addition, we saw that the space of refinements (alternatives) has a
significant impact on the final predictions. It would thus be
worthwhile to further explore different notions of refinement, seeking
better fits with our own experimental patterns and then validating
those conclusions in follow-up experiments using our experimental
items, or applying the resulting models in new domains.  We have made
publicly available all the data and code associated with this paper in
an effort to encourage these new strands of theory development and
quantitative assessment.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\small
\bibliographystyle{sp}
\setlength{\bibsep}{0pt}
\bibliography{embedded-scalars-bib}

\end{document}

